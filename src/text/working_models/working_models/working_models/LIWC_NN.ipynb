{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhh9SnNXzhc9"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"daniilfilienko.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1KSDy5BaDe6vigFqwminFi2HsiGXEL6t1\n",
        "\"\"\"\n",
        "\n",
        "# ML in Python, homework 3\n",
        "# name: Martine De Cock\n",
        "# description: Neural network for predicting personality of Facebook users\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "# Loading the data\n",
        "# There are 9500 users (rows)\n",
        "# There are 81 columns for the LIWC features followed by columns for\n",
        "# openness, conscientiousness, extraversion, agreeableness, neuroticism\n",
        "# As the target variable, we select the extraversion column (column 83)\n",
        "df = pd.read_csv(\"LIWC.csv\", delimiter=\",\")\n",
        "train_df = df.drop(\"ope\", axis='columns')\n",
        "train_df = train_df.drop(\"gender\", axis='columns')\n",
        "train_df = train_df.drop(\"con\", axis='columns')\n",
        "train_df = train_df.drop(\"ext\", axis='columns')\n",
        "train_df = train_df.drop(\"agr\", axis='columns')\n",
        "train_df = train_df.drop(\"neu\", axis='columns')\n",
        "train_df = train_df.drop(\"userId\", axis='columns')\n",
        "train_df_label = df['ope']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "akkwysuPzjN5",
        "outputId": "dd619820-fdac-4467-eff9-bc47f59060af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-aeb44b264594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# openness, conscientiousness, extraversion, agreeableness, neuroticism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# As the target variable, we select the extraversion column (column 83)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LIWC.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ope\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gender\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'LIWC.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_df,train_df_label, test_size=0.1)\n"
      ],
      "metadata": {
        "id": "JKUWcivUzkBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# baseline model\n",
        "def create_baseline():\n",
        " # create model\n",
        " model = Sequential()\n",
        " model.add(Dense(128, activation='relu'))\n",
        " model.add(Dense(1, activation='sigmoid'))\n",
        " # Compile model\n",
        " model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " return model\n",
        "model = create_baseline()\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=5)\n",
        "_, accuracy = model.evaluate(X_test, y_test)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQVjhXslzlPD",
        "outputId": "fdd6304b-2544-473d-8255-4fed370f17db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "1710/1710 [==============================] - 16s 5ms/step - loss: 3.2869 - accuracy: 0.6000\n",
            "Epoch 2/150\n",
            "1710/1710 [==============================] - 7s 4ms/step - loss: 1.1527 - accuracy: 0.6213\n",
            "Epoch 3/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 2.6398 - accuracy: 0.6271\n",
            "Epoch 4/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 2.7146 - accuracy: 0.6255\n",
            "Epoch 5/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 2.3278 - accuracy: 0.6292\n",
            "Epoch 6/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 1.7868 - accuracy: 0.6468\n",
            "Epoch 7/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 1.3825 - accuracy: 0.6462\n",
            "Epoch 8/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 2.0511 - accuracy: 0.6364\n",
            "Epoch 9/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 2.7664 - accuracy: 0.6477\n",
            "Epoch 10/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 1.1438 - accuracy: 0.6592\n",
            "Epoch 11/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 1.2417 - accuracy: 0.6658\n",
            "Epoch 12/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 2.6056 - accuracy: 0.6618\n",
            "Epoch 13/150\n",
            "1710/1710 [==============================] - 4s 3ms/step - loss: 1.1022 - accuracy: 0.6740\n",
            "Epoch 14/150\n",
            "1710/1710 [==============================] - 4s 3ms/step - loss: 1.4541 - accuracy: 0.6773\n",
            "Epoch 15/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 2.6692 - accuracy: 0.6778\n",
            "Epoch 16/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.7192 - accuracy: 0.6844\n",
            "Epoch 17/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.8447 - accuracy: 0.6873\n",
            "Epoch 18/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 2.0138 - accuracy: 0.6795\n",
            "Epoch 19/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.8503 - accuracy: 0.6835\n",
            "Epoch 20/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 1.1814 - accuracy: 0.6806\n",
            "Epoch 21/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 1.7165 - accuracy: 0.6811\n",
            "Epoch 22/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.6581 - accuracy: 0.6875\n",
            "Epoch 23/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.8262 - accuracy: 0.6889\n",
            "Epoch 24/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.9487 - accuracy: 0.6882\n",
            "Epoch 25/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.9691 - accuracy: 0.6923\n",
            "Epoch 26/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 1.2197 - accuracy: 0.6923\n",
            "Epoch 27/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.9697 - accuracy: 0.6942\n",
            "Epoch 28/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.6029 - accuracy: 0.6973\n",
            "Epoch 29/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.6643 - accuracy: 0.7000\n",
            "Epoch 30/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.6569 - accuracy: 0.6988\n",
            "Epoch 31/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.7425 - accuracy: 0.6956\n",
            "Epoch 32/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.6786 - accuracy: 0.7039\n",
            "Epoch 33/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.8326 - accuracy: 0.7000\n",
            "Epoch 34/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.6269 - accuracy: 0.7057\n",
            "Epoch 35/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.7632 - accuracy: 0.7013\n",
            "Epoch 36/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.8310 - accuracy: 0.6964\n",
            "Epoch 37/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5974 - accuracy: 0.7046\n",
            "Epoch 38/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.7459 - accuracy: 0.7077\n",
            "Epoch 39/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.6528 - accuracy: 0.7041\n",
            "Epoch 40/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.7235 - accuracy: 0.7080\n",
            "Epoch 41/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.6562 - accuracy: 0.7050\n",
            "Epoch 42/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5629 - accuracy: 0.7091\n",
            "Epoch 43/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5710 - accuracy: 0.7070\n",
            "Epoch 44/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5803 - accuracy: 0.7074\n",
            "Epoch 45/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.6505 - accuracy: 0.7094\n",
            "Epoch 46/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5593 - accuracy: 0.7102\n",
            "Epoch 47/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5708 - accuracy: 0.7095\n",
            "Epoch 48/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5578 - accuracy: 0.7097\n",
            "Epoch 49/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5663 - accuracy: 0.7109\n",
            "Epoch 50/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5556 - accuracy: 0.7140\n",
            "Epoch 51/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5508 - accuracy: 0.7125\n",
            "Epoch 52/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5541 - accuracy: 0.7145\n",
            "Epoch 53/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5543 - accuracy: 0.7166\n",
            "Epoch 54/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5762 - accuracy: 0.7159\n",
            "Epoch 55/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5663 - accuracy: 0.7150\n",
            "Epoch 56/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5446 - accuracy: 0.7164\n",
            "Epoch 57/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5461 - accuracy: 0.7171\n",
            "Epoch 58/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5499 - accuracy: 0.7193\n",
            "Epoch 59/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5696 - accuracy: 0.7168\n",
            "Epoch 60/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5464 - accuracy: 0.7184\n",
            "Epoch 61/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5368 - accuracy: 0.7250\n",
            "Epoch 62/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5397 - accuracy: 0.7198\n",
            "Epoch 63/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5565 - accuracy: 0.7249\n",
            "Epoch 64/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5451 - accuracy: 0.7214\n",
            "Epoch 65/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5485 - accuracy: 0.7178\n",
            "Epoch 66/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5493 - accuracy: 0.7193\n",
            "Epoch 67/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5472 - accuracy: 0.7208\n",
            "Epoch 68/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5490 - accuracy: 0.7227\n",
            "Epoch 69/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5323 - accuracy: 0.7277\n",
            "Epoch 70/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5414 - accuracy: 0.7262\n",
            "Epoch 71/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5399 - accuracy: 0.7276\n",
            "Epoch 72/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5584 - accuracy: 0.7267\n",
            "Epoch 73/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5377 - accuracy: 0.7282\n",
            "Epoch 74/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5328 - accuracy: 0.7267\n",
            "Epoch 75/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5416 - accuracy: 0.7239\n",
            "Epoch 76/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5390 - accuracy: 0.7283\n",
            "Epoch 77/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5308 - accuracy: 0.7291\n",
            "Epoch 78/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5390 - accuracy: 0.7263\n",
            "Epoch 79/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5539 - accuracy: 0.7322\n",
            "Epoch 80/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5293 - accuracy: 0.7304\n",
            "Epoch 81/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5268 - accuracy: 0.7350\n",
            "Epoch 82/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5256 - accuracy: 0.7268\n",
            "Epoch 83/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5392 - accuracy: 0.7295\n",
            "Epoch 84/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5266 - accuracy: 0.7327\n",
            "Epoch 85/150\n",
            "1710/1710 [==============================] - 4s 3ms/step - loss: 0.5747 - accuracy: 0.7285\n",
            "Epoch 86/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5287 - accuracy: 0.7311\n",
            "Epoch 87/150\n",
            "1710/1710 [==============================] - 4s 3ms/step - loss: 0.5281 - accuracy: 0.7312\n",
            "Epoch 88/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5404 - accuracy: 0.7297\n",
            "Epoch 89/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5242 - accuracy: 0.7323\n",
            "Epoch 90/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5222 - accuracy: 0.7338\n",
            "Epoch 91/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5410 - accuracy: 0.7299\n",
            "Epoch 92/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5387 - accuracy: 0.7310\n",
            "Epoch 93/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5306 - accuracy: 0.7313\n",
            "Epoch 94/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5352 - accuracy: 0.7342\n",
            "Epoch 95/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5224 - accuracy: 0.7340\n",
            "Epoch 96/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5234 - accuracy: 0.7322\n",
            "Epoch 97/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5262 - accuracy: 0.7343\n",
            "Epoch 98/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5190 - accuracy: 0.7332\n",
            "Epoch 99/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5209 - accuracy: 0.7340\n",
            "Epoch 100/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5580 - accuracy: 0.7346\n",
            "Epoch 101/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5250 - accuracy: 0.7352\n",
            "Epoch 102/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5736 - accuracy: 0.7386\n",
            "Epoch 103/150\n",
            "1710/1710 [==============================] - 4s 3ms/step - loss: 0.5289 - accuracy: 0.7382\n",
            "Epoch 104/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.7249 - accuracy: 0.7382\n",
            "Epoch 105/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5591 - accuracy: 0.7353\n",
            "Epoch 106/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5680 - accuracy: 0.7335\n",
            "Epoch 107/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5338 - accuracy: 0.7381\n",
            "Epoch 108/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.6085 - accuracy: 0.7359\n",
            "Epoch 109/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5260 - accuracy: 0.7381\n",
            "Epoch 110/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5130 - accuracy: 0.7414\n",
            "Epoch 111/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5144 - accuracy: 0.7357\n",
            "Epoch 112/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5151 - accuracy: 0.7401\n",
            "Epoch 113/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5180 - accuracy: 0.7386\n",
            "Epoch 114/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5444 - accuracy: 0.7388\n",
            "Epoch 115/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5245 - accuracy: 0.7409\n",
            "Epoch 116/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5123 - accuracy: 0.7377\n",
            "Epoch 117/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5135 - accuracy: 0.7395\n",
            "Epoch 118/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5232 - accuracy: 0.7398\n",
            "Epoch 119/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5122 - accuracy: 0.7396\n",
            "Epoch 120/150\n",
            "1710/1710 [==============================] - 4s 3ms/step - loss: 0.5131 - accuracy: 0.7421\n",
            "Epoch 121/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5177 - accuracy: 0.7389\n",
            "Epoch 122/150\n",
            "1710/1710 [==============================] - 4s 3ms/step - loss: 0.5122 - accuracy: 0.7406\n",
            "Epoch 123/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5330 - accuracy: 0.7429\n",
            "Epoch 124/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5438 - accuracy: 0.7400\n",
            "Epoch 125/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5154 - accuracy: 0.7441\n",
            "Epoch 126/150\n",
            "1710/1710 [==============================] - 4s 3ms/step - loss: 0.5168 - accuracy: 0.7407\n",
            "Epoch 127/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5184 - accuracy: 0.7435\n",
            "Epoch 128/150\n",
            "1710/1710 [==============================] - 4s 3ms/step - loss: 0.5268 - accuracy: 0.7373\n",
            "Epoch 129/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5062 - accuracy: 0.7422\n",
            "Epoch 130/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5061 - accuracy: 0.7429\n",
            "Epoch 131/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5122 - accuracy: 0.7437\n",
            "Epoch 132/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5158 - accuracy: 0.7392\n",
            "Epoch 133/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5061 - accuracy: 0.7464\n",
            "Epoch 134/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5111 - accuracy: 0.7437\n",
            "Epoch 135/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5059 - accuracy: 0.7468\n",
            "Epoch 136/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5074 - accuracy: 0.7429\n",
            "Epoch 137/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5038 - accuracy: 0.7450\n",
            "Epoch 138/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5030 - accuracy: 0.7405\n",
            "Epoch 139/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5049 - accuracy: 0.7440\n",
            "Epoch 140/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5108 - accuracy: 0.7423\n",
            "Epoch 141/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5078 - accuracy: 0.7467\n",
            "Epoch 142/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5044 - accuracy: 0.7454\n",
            "Epoch 143/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5032 - accuracy: 0.7480\n",
            "Epoch 144/150\n",
            "1710/1710 [==============================] - 4s 3ms/step - loss: 0.6763 - accuracy: 0.7420\n",
            "Epoch 145/150\n",
            "1710/1710 [==============================] - 4s 3ms/step - loss: 0.5027 - accuracy: 0.7462\n",
            "Epoch 146/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5009 - accuracy: 0.7447\n",
            "Epoch 147/150\n",
            "1710/1710 [==============================] - 4s 3ms/step - loss: 0.4992 - accuracy: 0.7488\n",
            "Epoch 148/150\n",
            "1710/1710 [==============================] - 5s 3ms/step - loss: 0.5087 - accuracy: 0.7470\n",
            "Epoch 149/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5161 - accuracy: 0.7487\n",
            "Epoch 150/150\n",
            "1710/1710 [==============================] - 4s 2ms/step - loss: 0.5243 - accuracy: 0.7468\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.1606 - accuracy: 0.6495\n",
            "Accuracy: 64.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(train_df)"
      ],
      "metadata": {
        "id": "kX5fz88F7Hmg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "230a7238-19b2-4cdc-dd34-e93b97986dfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "297/297 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_pred_norm = np.around(y_pred)\n",
        "y_pred_norm = np.asarray(y_pred_norm, dtype = 'int')"
      ],
      "metadata": {
        "id": "RoStUhABFnfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_norm[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srg_311HGHU4",
        "outputId": "a22bb07a-c899-48e3-ee8d-2a88483f5315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To mount drive as a local folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/MyDrive\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlzrtSFnAmCb",
        "outputId": "c937480c-7733-4201-9433-981cbc5039cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p saved_model\n",
        "model.save('saved_model/LIWC') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JguD7R44-2_H",
        "outputId": "cf0ae51c-897d-481a-848c-b7964ce5ccf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy with neural network:', metrics.accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "QNcp_pcOzrpE",
        "outputId": "d2754d52-3402-4b96-92fc-e6d9a9aac96e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-9c7e2bca1b62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MSE with neural network:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
          ]
        }
      ]
    }
  ]
}